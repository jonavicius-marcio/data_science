{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d564db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a557257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto de exemplo\n",
    "texto = \"Isso é um exemplo de como dividir um texto em n-grams.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a61126ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize o texto em palavras\n",
    "palavras = nltk.word_tokenize(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5140bfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Isso',)\n",
      "('é',)\n",
      "('um',)\n",
      "('exemplo',)\n",
      "('de',)\n",
      "('como',)\n",
      "('dividir',)\n",
      "('um',)\n",
      "('texto',)\n",
      "('em',)\n",
      "('n-grams',)\n",
      "('.',)\n"
     ]
    }
   ],
   "source": [
    "# Defina o valor de N para os N-grams\n",
    "N = 1\n",
    "\n",
    "# Crie os N-grams\n",
    "n_grams = list(ngrams(palavras, N))\n",
    "\n",
    "# Exiba os N-grams\n",
    "for n_gram in n_grams:\n",
    "    print(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edd3c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "103ad27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = np.array([4,8,16,32,64,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5519b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = [[1 , 2]]\n",
    "test_2 = [3 , 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e1d39fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bdc1e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7df0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8155823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Marcio\n",
      "[nltk_data]     Rodrigues\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76cd75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_N_grams(text,ngram=1):\n",
    "    words=[word for word in text.split(\" \") if word not in set(stopwords.words('english'))]  \n",
    "    print(\"Sentence after removing stopwords:\",words)\n",
    "    temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "    ans=[' '.join(ngram) for ngram in temp]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63d896ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence after removing stopwords: ['The', 'sun', 'rises', 'east']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The sun', 'sun rises', 'rises east']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_N_grams(\"The sun rises in the east\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631a1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c0cfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = \"The sun cooking in the east\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "186c0d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a632697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RegexpStemmer\n",
      "The sun cook in the east\n",
      "cookery\n"
     ]
    }
   ],
   "source": [
    "stemmer3 = RegexpStemmer('ing')\n",
    "# Aplica o Stemmer\n",
    "print(\"\\nRegexpStemmer\")\n",
    "print(stemmer3.stem(teste))\n",
    "print(stemmer3.stem('cookery'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498aae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2b4fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PorterStemmer\n",
      "cook\n",
      "cookeri\n",
      "\n",
      "LancasterStemmer\n",
      "cook\n",
      "cookery\n",
      "\n",
      "RegexpStemmer\n",
      "cook\n",
      "cookery\n",
      "\n",
      "SnowballStemmer\n",
      "tudo b\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Cria o Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Aplica o Stemmer\n",
    "print(\"\\nPorterStemmer\")\n",
    "print(stemmer.stem('cooking'))\n",
    "print(stemmer.stem('cookery'))\n",
    "\n",
    "# Cria o Stemmer\n",
    "stemmer2 = LancasterStemmer()\n",
    "\n",
    "# Aplica o Stemmer\n",
    "print(\"\\nLancasterStemmer\")\n",
    "print(stemmer2.stem('cooking'))\n",
    "print(stemmer2.stem('cookery'))\n",
    "\n",
    "# Cria o Stemmer\n",
    "stemmer3 = RegexpStemmer('ing')\n",
    "\n",
    "# Aplica o Stemmer\n",
    "print(\"\\nRegexpStemmer\")\n",
    "print(stemmer3.stem('cooking'))\n",
    "print(stemmer3.stem('cookery'))\n",
    "\n",
    "# Cria o Stemmer\n",
    "SnowballStemmer.languages\n",
    "portuguese_stemmer = SnowballStemmer('portuguese')\n",
    "print(\"\\nSnowballStemmer\")\n",
    "print(portuguese_stemmer.stem('Tudo bem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30509101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
